#+TITLE: Multilingual Dependency Parsing
* Introduction
This project is my implementation of an arc-eager transition-based dependency parser based on the Joakim Nivre's Malt Parser. The assignment and provided code comes from Professor Dragomir Radev's course Introduction to Natural Language Processing on Coursera.

The parser acheives the following top scores
- Swedish:
  - Unlabeled Attachment Score: 0.886476797451
  - Labeled Attachment Score: 0.834295956981
- Danish:
  - UAS: 0.930817610063
  - LAS: 0.899371069182
- English:
  - UAS: 0.933962264151
  - LAS: 0.911949685535

The arc-eager parser is a simple and elegant parser, able to acheive very high levels of accuracy without relying on any form of search.
* Parser Performance
** With ~badfeatures.model~
In the initial step of this project, I implemented the transition parser in ~transition.py~. This allowed the parser to move through the proper configurations necessary to parse data.

The model provided for this stage, ~badfeatures.model~, was trained on 200 random sentences of the Swedish data. When evaluated against the Swedish test corpush it returned the following scores:
- UAS: 0.229635530771
- LAS: 0.125672176857

As indicated by the name, the ~badfeatures~ model was intended as a baseline to demonstrate an inferior feature extractor.

Some of the features tested in this model were:
- LEX Buffer 0
- LEX Stack 0
** Adding features
*** Swedish
For Swedish, I roughly followed the feature sequence implemented in Nilson and Nugues (2010). I was also inspired by features mentioned by Chris Manning.
**** POSTAG Buffer 0
Testing the fine part of speech tag of the first word on the buffer had a very significant effect. The scores increased to the following:
- UAS: 0.533559051982
- LAS: 0.393945429197

For implementation, see the section of ~featureextractor.py~ following the comment ~# POSTAG Buffer 0~
**** POSTAG Stack 0
Testing the fine part of speech tag of the first word on the stack also had a significant effect. The scores increased to the following:
- UAS: 0.704043019319
- LAS: 0.602668791077

For implementation, see the section of ~featureextractor.py~ following the comment ~# POSTAG Stack 0~
**** POSTAG Buffer 1
Testing the fine POS tag of the second word on the buffer had a small effect, increasing to the following scores:
- UAS: 0.749850627365
- LAS: 0.644891455885

For implementation, see corresponding comment in ~featureextractor.py~, as above.
**** POSTAG Stack 1
Testing the fine POS tag of the second word on the stack had a small effect, increasing to the following scores:
- UAS: 0.774148575981
- LAS: 0.66421031667
**** FORM Buffer 1
Testing the form of the second word on the buffer had a very small effect:
- UAS: 0.780123481378
- LAS: 0.667596096395
**** Distance
Testing the distance (number of tokens) between the head of the buffer and the last word on the stack had a small effect:
- UAS: 0.791077474607
- LAS: 0.681139215296
**** Dependents Buffer 0
Testing the dependents of the first token of the buffer had a significant effect:
- UAS: 0.837482573193
- LAS: 0.750049790878
**** Dependents Stack 0
Finally, testing the dependents of the first token of the stack had a significant effect:
- UAS: 0.886476797451
- LAS: 0.834295956981
**** ID
Note that unlike English and Danish, considering the token's ID does /not/ improve the scores for Swedish:
- UAS: 0.885281816371
- LAS: 0.830312686716
  
See below for English and Danish scores.
*** Danish
**** Based on Swedish
Given the same features indicated above for Swedish, the model's performance on the Danish data is a bit better:
- UAS: 0.89500998004
- LAS: 0.858682634731
**** ID Stack 0
Unlike Swedish, considering the token's ID slightly improves its scores:
- UAS: 0.905389221557
- LAS: 0.867065868263
*** English
**** Based on Swedish
Given the same features indicated above for Swedish, the model's performance on the English data is significantly better:
- UAS: 0.930817610063
- LAS: 0.899371069182
**** ID Stack 0
Unlike Swedish but like Danish, considering the token's ID slightly improves its scores:
- UAS: 0.933962264151
- LAS: 0.911949685535
